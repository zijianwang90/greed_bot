"""
æ•°æ®è·å–æ¨¡å—
ä»å„ç§æ¥æºè·å–ææ…Œè´ªå©ªæŒ‡æ•°å’Œå…¶ä»–å¸‚åœºæŒ‡æ ‡æ•°æ®
"""

import json
import logging
import re
import asyncio
from typing import Dict, List, Optional, Tuple
from datetime import datetime, timedelta
import aiohttp
from bs4 import BeautifulSoup
import pandas as pd

from config import (
    CNN_FEAR_GREED_API,
    BACKUP_DATA_SOURCE,
    REQUEST_TIMEOUT,
    MAX_RETRIES
)

logger = logging.getLogger(__name__)


class FearGreedDataFetcher:
    """ææ…Œè´ªå©ªæŒ‡æ•°æ•°æ®è·å–å™¨"""
    
    def __init__(self):
        self.session = None
        
    async def __aenter__(self):
        # è®¾ç½®æµè§ˆå™¨å¤´éƒ¨ä»¥é¿å…åçˆ¬è™«æ£€æµ‹ - é’ˆå¯¹Yahoo Financeä¼˜åŒ–
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7',
            'Accept-Encoding': 'gzip, deflate, br',
            'Cache-Control': 'no-cache',
            'Connection': 'keep-alive',
            'DNT': '1',
            'Pragma': 'no-cache',
            'Referer': 'https://finance.yahoo.com/',
            'Sec-Ch-Ua': '"Not_A Brand";v="8", "Chromium";v="120", "Google Chrome";v="120"',
            'Sec-Ch-Ua-Mobile': '?0',
            'Sec-Ch-Ua-Platform': '"macOS"',
            'Sec-Fetch-Dest': 'empty',
            'Sec-Fetch-Mode': 'cors',
            'Sec-Fetch-Site': 'same-site',
            'Upgrade-Insecure-Requests': '1',
        }
        
        self.session = aiohttp.ClientSession(
            timeout=aiohttp.ClientTimeout(total=REQUEST_TIMEOUT),
            headers=headers
        )
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    async def get_current_fear_greed_index(self) -> Optional[Dict]:
        """è·å–å½“å‰ææ…Œè´ªå©ªæŒ‡æ•°"""
        try:
            # å°è¯•ä» CNN å®˜æ–¹ API è·å–
            logger.info("å°è¯•ä» CNN API è·å–ææ…Œè´ªå©ªæŒ‡æ•°...")
            data = await self._fetch_from_cnn_api()
            if data:
                logger.info("æˆåŠŸä» CNN API è·å–æ•°æ®")
                return data
                
            # å¤‡ç”¨æ–¹æ¡ˆï¼šä» Alternative.me API è·å–
            logger.warning("CNN API å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ•°æ®æº (Alternative.me)...")
            backup_data = await self._fetch_from_backup_source()
            if backup_data:
                logger.info("æˆåŠŸä»å¤‡ç”¨æ•°æ®æºè·å–æ•°æ®")
                return backup_data
            else:
                logger.error("æ‰€æœ‰æ•°æ®æºéƒ½å¤±è´¥äº†")
                return None
            
        except Exception as e:
            logger.error(f"è·å–ææ…Œè´ªå©ªæŒ‡æ•°å¤±è´¥: {e}")
            return None
    
    async def _fetch_from_cnn_api(self) -> Optional[Dict]:
        """ä» CNN API è·å–æ•°æ®"""
        for attempt in range(MAX_RETRIES):
            try:
                # æ·»åŠ ä¸€äº›éšæœºå»¶è¿Ÿä»¥é¿å…è¢«æ£€æµ‹ä¸ºè‡ªåŠ¨åŒ–è¯·æ±‚
                if attempt > 0:
                    import random
                    await asyncio.sleep(random.uniform(1, 3))
                
                async with self.session.get(CNN_FEAR_GREED_API) as response:
                    if response.status == 200:
                        data = await response.json()
                        return self._parse_cnn_data(data)
                    elif response.status == 418:
                        logger.warning(f"CNN API æ‹’ç»è¯·æ±‚ (çŠ¶æ€ç  418) - å°è¯• {attempt + 1}/{MAX_RETRIES}")
                        if attempt == MAX_RETRIES - 1:
                            logger.error("CNN API æŒç»­è¿”å› 418 çŠ¶æ€ç ï¼Œå¯èƒ½è¢«åçˆ¬è™«ç³»ç»Ÿé˜»æ­¢")
                        continue
                    else:
                        logger.warning(f"CNN API è¿”å›çŠ¶æ€ç : {response.status} - å°è¯• {attempt + 1}/{MAX_RETRIES}")
                        continue
                        
            except Exception as e:
                logger.error(f"ä» CNN API è·å–æ•°æ®å¤±è´¥ (å°è¯• {attempt + 1}/{MAX_RETRIES}): {e}")
                if attempt == MAX_RETRIES - 1:
                    return None
                continue
        
        return None
    
    def _parse_cnn_data(self, data: Dict) -> Dict:
        """è§£æ CNN API æ•°æ®"""
        try:
            fear_greed_data = data.get('fear_and_greed', {})
            
            current_score = fear_greed_data.get('score', 0)
            rating = fear_greed_data.get('rating', 'Unknown')
            last_update = fear_greed_data.get('timestamp', '')
            
            # è·å–å†å²æ•°æ®
            historical_data = fear_greed_data.get('previous_close', 0)
            week_ago = fear_greed_data.get('previous_1_week', 0)
            month_ago = fear_greed_data.get('previous_1_month', 0)
            year_ago = fear_greed_data.get('previous_1_year', 0)
            
            return {
                'current_value': current_score,
                'rating': rating,
                'last_update': last_update,
                'previous_close': historical_data,
                'week_ago': week_ago,
                'month_ago': month_ago,
                'year_ago': year_ago,
                'source': 'CNN Official API'
            }
            
        except Exception as e:
            logger.error(f"è§£æ CNN æ•°æ®å¤±è´¥: {e}")
            return {}
    
    async def _fetch_from_backup_source(self) -> Optional[Dict]:
        """ä»å¤‡ç”¨æ•°æ®æºè·å–æ•°æ®"""
        try:
            async with self.session.get(BACKUP_DATA_SOURCE) as response:
                if response.status == 200:
                    data = await response.json()
                    return self._parse_backup_data(data)
                else:
                    logger.warning(f"å¤‡ç”¨æ•°æ®æºè¿”å›çŠ¶æ€ç : {response.status}")
                    return None
                    
        except Exception as e:
            logger.error(f"ä»å¤‡ç”¨æ•°æ®æºè·å–æ•°æ®å¤±è´¥: {e}")
            return None
    
    def _parse_backup_data(self, data: Dict) -> Dict:
        """è§£æå¤‡ç”¨æ•°æ®æºçš„ JSON (Alternative.me API)"""
        try:
            # Alternative.me API è¿”å›æ ¼å¼ï¼š
            # {
            #   "name": "Fear and Greed Index",
            #   "data": [
            #     {
            #       "value": "40",
            #       "value_classification": "Fear",
            #       "timestamp": "1551157200",
            #       "time_until_update": "68499"
            #     }
            #   ]
            # }
            
            if 'data' in data and len(data['data']) > 0:
                latest_data = data['data'][0]
                
                current_value = int(latest_data.get('value', 50))
                rating = latest_data.get('value_classification', 'Unknown')
                timestamp = latest_data.get('timestamp', '')
                
                # è½¬æ¢æ—¶é—´æˆ³
                if timestamp:
                    try:
                        dt = datetime.fromtimestamp(int(timestamp))
                        last_update = dt.isoformat()
                    except:
                        last_update = datetime.now().isoformat()
                else:
                    last_update = datetime.now().isoformat()
                
                return {
                    'current_value': current_value,
                    'rating': rating,
                    'last_update': last_update,
                    'previous_close': None,
                    'week_ago': None,
                    'month_ago': None,
                    'year_ago': None,
                    'source': 'Alternative.me API'
                }
            else:
                logger.warning("å¤‡ç”¨æ•°æ®æºè¿”å›çš„æ•°æ®æ ¼å¼ä¸æ­£ç¡®")
                return {}
            
        except Exception as e:
            logger.error(f"è§£æå¤‡ç”¨æ•°æ®å¤±è´¥: {e}")
            return {}
    
    def _get_rating_from_value(self, value: int) -> str:
        """æ ¹æ®æ•°å€¼è·å–è¯„çº§"""
        if value <= 25:
            return "Extreme Fear"
        elif value <= 45:
            return "Fear"  
        elif value <= 55:
            return "Neutral"
        elif value <= 75:
            return "Greed"
        else:
            return "Extreme Greed"
    
    async def get_vix_data(self) -> Optional[Dict]:
        """è·å– VIX æ³¢åŠ¨ç‡æŒ‡æ•°æ•°æ®"""
        # å°è¯•å¤šä¸ªæ•°æ®æºï¼ŒåŒ…æ‹¬æ›¿ä»£æº
        vix_sources = [
            {
                'name': 'Finnhub VIX',
                'url': 'https://finnhub.io/api/v1/quote?symbol=VIX&token=demo',
                'parser': self._parse_finnhub_data
            },
            {
                'name': 'Alpha Vantage VIX',
                'url': 'https://www.alphavantage.co/query?function=GLOBAL_QUOTE&symbol=VIX&apikey=demo',
                'parser': self._parse_alpha_vantage_data
            },
            {
                'name': 'IEX Cloud VIX',
                'url': 'https://cloud.iexapis.com/stable/stock/vix/quote?token=Tpk_059b97af715d417d9f49f50b51b1c448',
                'parser': self._parse_iex_data
            },
            {
                'name': 'Yahoo Finance Chart API', 
                'url': 'https://query1.finance.yahoo.com/v8/finance/chart/^VIX',
                'parser': self._parse_yahoo_chart_data
            },
            {
                'name': 'Yahoo Finance Quote API',
                'url': 'https://query1.finance.yahoo.com/v7/finance/quote?symbols=^VIX',
                'parser': self._parse_yahoo_quote_data
            }
        ]
        
        for i, source in enumerate(vix_sources):
            try:
                logger.info(f"Trying VIX source {i+1}/{len(vix_sources)}: {source['name']}")
                
                # æ·»åŠ å»¶è¿Ÿï¼Œå¯¹Yahoo Finance APIä½¿ç”¨æ›´é•¿å»¶è¿Ÿ
                import random
                is_yahoo = 'yahoo' in source['name'].lower()
                delay = random.uniform(3.0, 6.0) if is_yahoo else random.uniform(0.5, 1.5)
                logger.info(f"Waiting {delay:.1f}s before request to {source['name']}...")
                await asyncio.sleep(delay)
                
                # æ ¹æ®APIç±»å‹è®¾ç½®ç‰¹å®šè¯·æ±‚å¤´
                api_headers = {}
                if is_yahoo:
                    api_headers = {
                        'Accept': 'application/json',
                        'Cache-Control': 'no-cache',
                        'Pragma': 'no-cache',
                        'Referer': 'https://finance.yahoo.com/quote/%5EVIX/',
                        'X-Requested-With': 'XMLHttpRequest',
                    }
                elif 'alpha' in source['name'].lower():
                    api_headers = {
                        'Accept': 'application/json',
                        'User-Agent': 'VIX-Bot/1.0',
                    }
                elif 'finnhub' in source['name'].lower():
                    api_headers = {
                        'Accept': 'application/json',
                        'X-Finnhub-Token': 'demo',
                    }
                elif 'iex' in source['name'].lower():
                    api_headers = {
                        'Accept': 'application/json',
                        'User-Agent': 'VIX-Greed-Bot/1.0',
                    }
                
                async with self.session.get(source['url'], headers=api_headers) as response:
                    logger.info(f"VIX {source['name']} response status: {response.status}")
                    
                    if response.status == 200:
                        data = await response.json()
                        logger.info(f"VIX {source['name']} data structure: {type(data)} with keys: {list(data.keys()) if isinstance(data, dict) else 'Not a dict'}")
                        parsed_data = source['parser'](data)
                        
                        if parsed_data and parsed_data.get('current_value', 0) > 0:
                            logger.info(f"âœ… Successfully got VIX data from {source['name']}: current_value={parsed_data.get('current_value')}")
                            return parsed_data
                        else:
                            logger.warning(f"VIX {source['name']} returned invalid data: {parsed_data}")
                    
                    elif response.status == 429:
                        logger.warning(f"âš ï¸ VIX {source['name']} rate limited (429), waiting longer before next source...")
                        await asyncio.sleep(random.uniform(5.0, 8.0))  # æ›´é•¿çš„ç­‰å¾…æ—¶é—´
                        continue
                    elif response.status in [403, 404]:
                        logger.error(f"âŒ VIX {source['name']} access denied or not found ({response.status})")
                        continue
                    else:
                        logger.error(f"âŒ VIX {source['name']} returned status {response.status}")
                        response_text = await response.text()
                        logger.error(f"Response body: {response_text[:300]}...")
                        continue
                        
            except asyncio.TimeoutError:
                logger.error(f"â° VIX {source['name']} timed out")
                continue
            except Exception as e:
                logger.error(f"ğŸ’¥ VIX {source['name']} failed with exception: {e}")
                continue
        
        # å¦‚æœæ‰€æœ‰æºéƒ½å¤±è´¥ï¼Œè¿”å›æ¨¡æ‹Ÿæ•°æ®ç”¨äºæ¼”ç¤º
        logger.warning("All VIX sources failed, returning demo data")
        return self._get_demo_vix_data()

    def _parse_finnhub_data(self, data: Dict) -> Optional[Dict]:
        """è§£æFinnhub APIå“åº”"""
        try:
            current_price = float(data.get('c', 0))  # current price
            previous_close = float(data.get('pc', 0))  # previous close
            
            if current_price > 0:
                change = current_price - previous_close
                change_percent = (change / previous_close * 100) if previous_close > 0 else 0
                
                return {
                    'current_value': current_price,
                    'previous_close': previous_close,
                    'change': change,
                    'change_percent': change_percent,
                    'last_update': datetime.now().isoformat(),
                    'source': 'Finnhub',
                    'high': data.get('h', 0),
                    'low': data.get('l', 0),
                    'open': data.get('o', 0)
                }
            
            logger.warning("Finnhub data incomplete")
            return None
            
        except (KeyError, ValueError, TypeError) as e:
            logger.error(f"Error parsing Finnhub data: {e}")
            return None

    def _parse_iex_data(self, data: Dict) -> Optional[Dict]:
        """è§£æIEX Cloud APIå“åº”"""
        try:
            current_price = float(data.get('latestPrice', 0))
            previous_close = float(data.get('previousClose', 0))
            
            if current_price > 0:
                change = float(data.get('change', 0))
                change_percent = float(data.get('changePercent', 0)) * 100
                
                return {
                    'current_value': current_price,
                    'previous_close': previous_close,
                    'change': change,
                    'change_percent': change_percent,
                    'last_update': data.get('latestUpdate', datetime.now().isoformat()),
                    'source': 'IEX Cloud',
                    'market_cap': data.get('marketCap'),
                    'volume': data.get('volume')
                }
            
            logger.warning("IEX Cloud data incomplete")
            return None
            
        except (KeyError, ValueError, TypeError) as e:
            logger.error(f"Error parsing IEX Cloud data: {e}")
            return None

    def _parse_alpha_vantage_data(self, data: Dict) -> Optional[Dict]:
        """è§£æAlpha Vantage APIå“åº”"""
        try:
            if 'Global Quote' in data:
                quote = data['Global Quote']
                current_price = float(quote.get('05. price', 0))
                previous_close = float(quote.get('08. previous close', 0))
                
                if current_price > 0:
                    change = current_price - previous_close
                    change_percent = (change / previous_close * 100) if previous_close > 0 else 0
                    
                    return {
                        'current_value': current_price,
                        'previous_close': previous_close,
                        'change': change,
                        'change_percent': change_percent,
                        'last_update': datetime.now().isoformat(),
                        'source': 'Alpha Vantage',
                        'symbol': quote.get('01. symbol', 'VIX')
                    }
            
            logger.warning("Alpha Vantage data structure not recognized")
            return None
            
        except (KeyError, ValueError, TypeError) as e:
            logger.error(f"Error parsing Alpha Vantage data: {e}")
            return None

    def _parse_marketwatch_data(self, data: Dict) -> Optional[Dict]:
        """è§£æMarketWatch APIå“åº”"""
        try:
            if 'TimeValueCollection' in data and data['TimeValueCollection']:
                recent_data = data['TimeValueCollection'][-1]  # æœ€æ–°æ•°æ®
                previous_data = data['TimeValueCollection'][-2] if len(data['TimeValueCollection']) > 1 else recent_data
                
                current_price = float(recent_data.get('Value', 0))
                previous_price = float(previous_data.get('Value', 0))
                
                if current_price > 0:
                    change = current_price - previous_price
                    change_percent = (change / previous_price * 100) if previous_price > 0 else 0
                    
                    return {
                        'current_value': current_price,
                        'previous_close': previous_price,
                        'change': change,
                        'change_percent': change_percent,
                        'last_update': recent_data.get('TimeStamp', datetime.now().isoformat()),
                        'source': 'MarketWatch'
                    }
            
            logger.warning("MarketWatch data structure not recognized")
            return None
            
        except (KeyError, ValueError, TypeError) as e:
            logger.error(f"Error parsing MarketWatch data: {e}")
        return None
    
    def _parse_yahoo_quote_data(self, data: Dict) -> Dict:
        """è§£æYahoo Finance Quote APIæ•°æ®"""
        try:
            if 'quoteResponse' not in data:
                logger.error("No 'quoteResponse' in Yahoo quote data")
                return {}
                
            quote_response = data['quoteResponse']
            if 'result' not in quote_response or not quote_response['result']:
                logger.error("No 'result' in quote response")
                return {}
                
            result = quote_response['result'][0]
            logger.info(f"Yahoo quote result: {result}")
            
            current_price = result.get('regularMarketPrice', 0)
            previous_close = result.get('regularMarketPreviousClose', 0)
            
            if current_price == 0:
                current_price = result.get('bid', result.get('ask', 0))
            
            change = result.get('regularMarketChange', 0)
            change_percent = result.get('regularMarketChangePercent', 0)
            
            if change == 0 and previous_close > 0:
                change = current_price - previous_close
                change_percent = (change / previous_close) * 100
            
            parsed_result = {
                'current_value': round(current_price, 2),
                'previous_close': round(previous_close, 2),
                'change': round(change, 2),
                'change_percent': round(change_percent, 2),
                'last_update': datetime.now().isoformat(),
                'source': 'Yahoo Finance Quote API'
            }
            
            logger.info(f"Parsed Yahoo quote VIX data: {parsed_result}")
            return parsed_result
            
        except Exception as e:
            logger.error(f"è§£æYahoo Quote VIXæ•°æ®å¤±è´¥: {e}", exc_info=True)
            return {}
    
    def _get_demo_vix_data(self) -> Dict:
        """è·å–æ¼”ç¤ºVIXæ•°æ®"""
        import random
        
        # ç”Ÿæˆåˆç†èŒƒå›´å†…çš„VIXæ•°æ® (é€šå¸¸åœ¨10-80ä¹‹é—´)
        base_vix = random.uniform(15.0, 35.0)
        previous_close = base_vix + random.uniform(-2.0, 2.0)
        change = base_vix - previous_close
        change_percent = (change / previous_close) * 100
        
        demo_data = {
            'current_value': round(base_vix, 2),
            'previous_close': round(previous_close, 2),
            'change': round(change, 2),
            'change_percent': round(change_percent, 2),
            'last_update': datetime.now().isoformat(),
            'source': 'Demo Data',
            'is_demo': True
        }
        
        logger.info(f"Generated demo VIX data: {demo_data}")
        return demo_data
    
    def _parse_yahoo_chart_data(self, data: Dict) -> Dict:
        """è§£æYahoo Finance Chart APIæ•°æ®"""
        try:
            logger.info(f"Parsing VIX data structure: {data}")
            
            if 'chart' not in data:
                logger.error("No 'chart' key in VIX data")
                return {}
                
            chart = data['chart']
            if 'result' not in chart or not chart['result']:
                logger.error("No 'result' in chart data or result is empty")
                return {}
                
            result = chart['result'][0]
            logger.info(f"VIX result keys: {list(result.keys())}")
            
            if 'meta' not in result:
                logger.error("No 'meta' key in result")
                return {}
                
            meta = result['meta']
            logger.info(f"VIX meta data: {meta}")
            
            current_price = meta.get('regularMarketPrice', 0)
            previous_close = meta.get('previousClose', 0)
            
            if current_price == 0:
                logger.warning("Current price is 0, checking alternative fields")
                # Try alternative fields
                current_price = meta.get('currentPrice', 0)
                if current_price == 0:
                    current_price = meta.get('price', 0)
            
            change = current_price - previous_close if previous_close else 0
            change_percent = (change / previous_close) * 100 if previous_close else 0
            
            parsed_result = {
                'current_value': round(current_price, 2),
                'previous_close': round(previous_close, 2),
                'change': round(change, 2),
                'change_percent': round(change_percent, 2),
                'last_update': datetime.now().isoformat()
            }
            
            logger.info(f"Successfully parsed VIX data: {parsed_result}")
            return parsed_result
            
        except Exception as e:
            logger.error(f"è§£æ VIX æ•°æ®å¤±è´¥: {e}", exc_info=True)
            return {}
    
    async def get_put_call_ratio(self) -> Optional[Dict]:
        """è·å– Put/Call æ¯”ç‡æ•°æ®"""
        try:
            # CBOE Put/Call æ¯”ç‡
            url = "https://www.cboe.com/us/options/market_statistics/daily/"
            
            async with self.session.get(url) as response:
                if response.status == 200:
                    html = await response.text()
                    return self._parse_put_call_data(html)
                    
        except Exception as e:
            logger.error(f"è·å– Put/Call æ¯”ç‡å¤±è´¥: {e}")
            
        return None
    
    def _parse_put_call_data(self, html: str) -> Dict:
        """è§£æ Put/Call æ¯”ç‡æ•°æ®"""
        try:
            soup = BeautifulSoup(html, 'html.parser')
            
            # è¿™é‡Œéœ€è¦æ ¹æ® CBOE ç½‘ç«™çš„å®é™…ç»“æ„æ¥è§£æ
            # ç”±äºç½‘ç«™ç»“æ„å¯èƒ½å˜åŒ–ï¼Œè¿™é‡Œæä¾›ä¸€ä¸ªåŸºç¡€æ¡†æ¶
            
            ratio = 1.0  # é»˜è®¤å€¼
            
            return {
                'ratio': ratio,
                'last_update': datetime.now().isoformat(),
                'interpretation': 'Neutral' if 0.8 <= ratio <= 1.2 else ('Bearish' if ratio > 1.2 else 'Bullish')
            }
            
        except Exception as e:
            logger.error(f"è§£æ Put/Call æ•°æ®å¤±è´¥: {e}")
            return {}
    
    async def get_market_breadth(self) -> Optional[Dict]:
        """è·å–å¸‚åœºå¹¿åº¦æ•°æ®"""
        try:
            # NYSE æ¶¨è·Œè‚¡ç¥¨æ•°æ®
            url = "https://www.marketwatch.com/investing/index/adv"
            
            async with self.session.get(url) as response:
                if response.status == 200:
                    html = await response.text()
                    return self._parse_market_breadth_data(html)
                    
        except Exception as e:
            logger.error(f"è·å–å¸‚åœºå¹¿åº¦æ•°æ®å¤±è´¥: {e}")
            
        return None
    
    def _parse_market_breadth_data(self, html: str) -> Dict:
        """è§£æå¸‚åœºå¹¿åº¦æ•°æ®"""
        try:
            soup = BeautifulSoup(html, 'html.parser')
            
            # åŸºç¡€æ•°æ®ï¼Œå®é™…éœ€è¦æ ¹æ®ç½‘ç«™ç»“æ„è°ƒæ•´
            advancing = 2000
            declining = 1500
            unchanged = 500
            
            total = advancing + declining + unchanged
            advance_decline_ratio = advancing / declining if declining > 0 else 1.0
            
            return {
                'advancing': advancing,
                'declining': declining,
                'unchanged': unchanged,
                'advance_decline_ratio': round(advance_decline_ratio, 2),
                'breadth_thrust': advance_decline_ratio > 2.0,
                'last_update': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"è§£æå¸‚åœºå¹¿åº¦æ•°æ®å¤±è´¥: {e}")
            return {}


async def fetch_all_indicators() -> Dict:
    """è·å–æ‰€æœ‰å¸‚åœºæŒ‡æ ‡"""
    async with FearGreedDataFetcher() as fetcher:
        results = {}
        
        # å¹¶å‘è·å–æ‰€æœ‰æ•°æ®
        tasks = [
            fetcher.get_current_fear_greed_index(),
            fetcher.get_vix_data(),
            fetcher.get_put_call_ratio(),
            fetcher.get_market_breadth()
        ]
        
        try:
            fear_greed, vix, put_call, breadth = await asyncio.gather(*tasks, return_exceptions=True)
            
            if not isinstance(fear_greed, Exception) and fear_greed:
                results['fear_greed'] = fear_greed
                
            if not isinstance(vix, Exception) and vix:
                results['vix'] = vix
                
            if not isinstance(put_call, Exception) and put_call:
                results['put_call'] = put_call
                
            if not isinstance(breadth, Exception) and breadth:
                results['market_breadth'] = breadth
                
        except Exception as e:
            logger.error(f"è·å–å¸‚åœºæŒ‡æ ‡æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            
        return results


# ä¾¿æ·å‡½æ•°
async def get_fear_greed_index() -> Optional[Dict]:
    """è·å–ææ…Œè´ªå©ªæŒ‡æ•°çš„ä¾¿æ·å‡½æ•°"""
    async with FearGreedDataFetcher() as fetcher:
        return await fetcher.get_current_fear_greed_index()


# å…¼å®¹æ€§åˆ«å
class DataFetcher(FearGreedDataFetcher):
    """DataFetcher å…¼å®¹æ€§åˆ«å"""
    
    async def get_current_fear_greed_index(self) -> Optional[Dict]:
        """è·å–å½“å‰ææ…Œè´ªå©ªæŒ‡æ•° - å…¼å®¹æ€§æ–¹æ³•"""
        # ä½¿ç”¨ context manager æ¥ç®¡ç† session
        async with self:
            data = await super().get_current_fear_greed_index()
            if data:
                # è½¬æ¢æ•°æ®æ ¼å¼ä»¥åŒ¹é… handlers.py çš„é¢„æœŸ
                return {
                    'score': data.get('current_value', 0),
                    'rating': data.get('rating', 'Unknown'),
                    'timestamp': data.get('last_update', ''),
                    'previous_close': data.get('previous_close'),
                    'week_ago': data.get('week_ago'),
                    'month_ago': data.get('month_ago'),
                    'year_ago': data.get('year_ago'),
                    'source': data.get('source', 'Unknown')
                }
            return None 