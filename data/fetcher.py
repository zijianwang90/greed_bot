"""
æ•°æ®è·å–æ¨¡å—
ä»å„ç§æ¥æºè·å–ææ…Œè´ªå©ªæŒ‡æ•°å’Œå…¶ä»–å¸‚åœºæŒ‡æ ‡æ•°æ®
"""

import json
import logging
import re
import asyncio
from typing import Dict, List, Optional, Tuple
from datetime import datetime, timedelta
import aiohttp
from bs4 import BeautifulSoup
import pandas as pd

from config import (
    CNN_FEAR_GREED_API,
    BACKUP_DATA_SOURCE,
    REQUEST_TIMEOUT,
    MAX_RETRIES
)

logger = logging.getLogger(__name__)


class FearGreedDataFetcher:
    """ææ…Œè´ªå©ªæŒ‡æ•°æ•°æ®è·å–å™¨"""
    
    def __init__(self):
        self.session = None
        
    async def __aenter__(self):
        # è®¾ç½®æµè§ˆå™¨å¤´éƒ¨ä»¥é¿å…åçˆ¬è™«æ£€æµ‹ - é’ˆå¯¹Yahoo Financeä¼˜åŒ–
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7',
            'Accept-Encoding': 'gzip, deflate, br',
            'Cache-Control': 'no-cache',
            'Connection': 'keep-alive',
            'DNT': '1',
            'Pragma': 'no-cache',
            'Referer': 'https://finance.yahoo.com/',
            'Sec-Ch-Ua': '"Not_A Brand";v="8", "Chromium";v="120", "Google Chrome";v="120"',
            'Sec-Ch-Ua-Mobile': '?0',
            'Sec-Ch-Ua-Platform': '"macOS"',
            'Sec-Fetch-Dest': 'empty',
            'Sec-Fetch-Mode': 'cors',
            'Sec-Fetch-Site': 'same-site',
            'Upgrade-Insecure-Requests': '1',
        }
        
        self.session = aiohttp.ClientSession(
            timeout=aiohttp.ClientTimeout(total=REQUEST_TIMEOUT),
            headers=headers
        )
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    async def get_current_fear_greed_index(self) -> Optional[Dict]:
        """è·å–å½“å‰ææ…Œè´ªå©ªæŒ‡æ•°"""
        try:
            # å°è¯•ä» CNN å®˜æ–¹ API è·å–
            logger.info("å°è¯•ä» CNN API è·å–ææ…Œè´ªå©ªæŒ‡æ•°...")
            data = await self._fetch_from_cnn_api()
            if data:
                logger.info("æˆåŠŸä» CNN API è·å–æ•°æ®")
                return data
                
            # å¤‡ç”¨æ–¹æ¡ˆï¼šä» Alternative.me API è·å–
            logger.warning("CNN API å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ•°æ®æº (Alternative.me)...")
            backup_data = await self._fetch_from_backup_source()
            if backup_data:
                logger.info("æˆåŠŸä»å¤‡ç”¨æ•°æ®æºè·å–æ•°æ®")
                return backup_data
            else:
                logger.error("æ‰€æœ‰æ•°æ®æºéƒ½å¤±è´¥äº†")
                return None
            
        except Exception as e:
            logger.error(f"è·å–ææ…Œè´ªå©ªæŒ‡æ•°å¤±è´¥: {e}")
            return None
    
    async def _fetch_from_cnn_api(self) -> Optional[Dict]:
        """ä» CNN API è·å–æ•°æ®"""
        for attempt in range(MAX_RETRIES):
            try:
                # æ·»åŠ ä¸€äº›éšæœºå»¶è¿Ÿä»¥é¿å…è¢«æ£€æµ‹ä¸ºè‡ªåŠ¨åŒ–è¯·æ±‚
                if attempt > 0:
                    import random
                    await asyncio.sleep(random.uniform(1, 3))
                
                async with self.session.get(CNN_FEAR_GREED_API) as response:
                    if response.status == 200:
                        data = await response.json()
                        return self._parse_cnn_data(data)
                    elif response.status == 418:
                        logger.warning(f"CNN API æ‹’ç»è¯·æ±‚ (çŠ¶æ€ç  418) - å°è¯• {attempt + 1}/{MAX_RETRIES}")
                        if attempt == MAX_RETRIES - 1:
                            logger.error("CNN API æŒç»­è¿”å› 418 çŠ¶æ€ç ï¼Œå¯èƒ½è¢«åçˆ¬è™«ç³»ç»Ÿé˜»æ­¢")
                        continue
                    else:
                        logger.warning(f"CNN API è¿”å›çŠ¶æ€ç : {response.status} - å°è¯• {attempt + 1}/{MAX_RETRIES}")
                        continue
                        
            except Exception as e:
                logger.error(f"ä» CNN API è·å–æ•°æ®å¤±è´¥ (å°è¯• {attempt + 1}/{MAX_RETRIES}): {e}")
                if attempt == MAX_RETRIES - 1:
                    return None
                continue
        
        return None
    
    def _parse_cnn_data(self, data: Dict) -> Dict:
        """è§£æ CNN API æ•°æ®"""
        try:
            fear_greed_data = data.get('fear_and_greed', {})
            
            current_score = fear_greed_data.get('score', 0)
            rating = fear_greed_data.get('rating', 'Unknown')
            last_update = fear_greed_data.get('timestamp', '')
            
            # è·å–å†å²æ•°æ®
            historical_data = fear_greed_data.get('previous_close', 0)
            week_ago = fear_greed_data.get('previous_1_week', 0)
            month_ago = fear_greed_data.get('previous_1_month', 0)
            year_ago = fear_greed_data.get('previous_1_year', 0)
            
            return {
                'current_value': current_score,
                'rating': rating,
                'last_update': last_update,
                'previous_close': historical_data,
                'week_ago': week_ago,
                'month_ago': month_ago,
                'year_ago': year_ago,
                'source': 'CNN Official API'
            }
            
        except Exception as e:
            logger.error(f"è§£æ CNN æ•°æ®å¤±è´¥: {e}")
            return {}
    
    async def _fetch_from_backup_source(self) -> Optional[Dict]:
        """ä»å¤‡ç”¨æ•°æ®æºè·å–æ•°æ®"""
        try:
            async with self.session.get(BACKUP_DATA_SOURCE) as response:
                if response.status == 200:
                    data = await response.json()
                    return self._parse_backup_data(data)
                else:
                    logger.warning(f"å¤‡ç”¨æ•°æ®æºè¿”å›çŠ¶æ€ç : {response.status}")
                    return None
                    
        except Exception as e:
            logger.error(f"ä»å¤‡ç”¨æ•°æ®æºè·å–æ•°æ®å¤±è´¥: {e}")
            return None
    
    def _parse_backup_data(self, data: Dict) -> Dict:
        """è§£æå¤‡ç”¨æ•°æ®æºçš„ JSON (Alternative.me API)"""
        try:
            # Alternative.me API è¿”å›æ ¼å¼ï¼š
            # {
            #   "name": "Fear and Greed Index",
            #   "data": [
            #     {
            #       "value": "40",
            #       "value_classification": "Fear",
            #       "timestamp": "1551157200",
            #       "time_until_update": "68499"
            #     }
            #   ]
            # }
            
            if 'data' in data and len(data['data']) > 0:
                latest_data = data['data'][0]
                
                current_value = int(latest_data.get('value', 50))
                rating = latest_data.get('value_classification', 'Unknown')
                timestamp = latest_data.get('timestamp', '')
                
                # è½¬æ¢æ—¶é—´æˆ³
                if timestamp:
                    try:
                        dt = datetime.fromtimestamp(int(timestamp))
                        last_update = dt.isoformat()
                    except:
                        last_update = datetime.now().isoformat()
                else:
                    last_update = datetime.now().isoformat()
                
                return {
                    'current_value': current_value,
                    'rating': rating,
                    'last_update': last_update,
                    'previous_close': None,
                    'week_ago': None,
                    'month_ago': None,
                    'year_ago': None,
                    'source': 'Alternative.me API'
                }
            else:
                logger.warning("å¤‡ç”¨æ•°æ®æºè¿”å›çš„æ•°æ®æ ¼å¼ä¸æ­£ç¡®")
                return {}
            
        except Exception as e:
            logger.error(f"è§£æå¤‡ç”¨æ•°æ®å¤±è´¥: {e}")
            return {}
    
    def _get_rating_from_value(self, value: int) -> str:
        """æ ¹æ®æ•°å€¼è·å–è¯„çº§"""
        if value <= 25:
            return "Extreme Fear"
        elif value <= 45:
            return "Fear"  
        elif value <= 55:
            return "Neutral"
        elif value <= 75:
            return "Greed"
        else:
            return "Extreme Greed"
    
    async def get_vix_data(self) -> Optional[Dict]:
        """è·å– VIX æ³¢åŠ¨ç‡æŒ‡æ•°æ•°æ® - ä½¿ç”¨ Alpha Vantage API"""
        try:
            import config_local
            api_key = config_local.ALPHA_VANTAGE_API_KEY
            url = f"https://www.alphavantage.co/query?function=GLOBAL_QUOTE&symbol=VIX&apikey={api_key}"
            
            logger.info("Fetching VIX data from Alpha Vantage API...")
            
            # ç®€å•çš„è¯·æ±‚å¤´
            headers = {
                'Accept': 'application/json',
                'User-Agent': 'VIX-Greed-Bot/1.0'
            }
            
            async with self.session.get(url, headers=headers) as response:
                logger.info(f"Alpha Vantage VIX API response status: {response.status}")
                
                if response.status == 200:
                    data = await response.json()
                    logger.info(f"Alpha Vantage data structure: {type(data)} with keys: {list(data.keys()) if isinstance(data, dict) else 'Not a dict'}")
                    
                    parsed_data = self._parse_alpha_vantage_data(data)
                    if parsed_data and parsed_data.get('current_value', 0) > 0:
                        logger.info(f"âœ… Successfully got VIX data from Alpha Vantage: current_value={parsed_data.get('current_value')}")
                        return parsed_data
                    else:
                        logger.warning(f"Alpha Vantage returned invalid data: {parsed_data}")
                
                elif response.status == 401:
                    logger.error("âŒ Alpha Vantage API key invalid or expired")
                elif response.status == 429:
                    logger.error("âŒ Alpha Vantage API rate limit exceeded")
                else:
                    logger.error(f"âŒ Alpha Vantage API returned status {response.status}")
                    response_text = await response.text()
                    logger.error(f"Response body: {response_text[:200]}...")
                        
        except Exception as e:
            logger.error(f"ğŸ’¥ Error fetching VIX data from Alpha Vantage: {e}")
        
        # å¦‚æœAlpha Vantageå¤±è´¥ï¼Œè¿”å›æ™ºèƒ½æ¼”ç¤ºæ•°æ®
        logger.warning("Alpha Vantage API failed, returning intelligent demo data")
        return self._get_demo_vix_data()

    def _parse_alpha_vantage_data(self, data: Dict) -> Optional[Dict]:
        """è§£æAlpha Vantage APIå“åº”"""
        try:
            if 'Global Quote' in data:
                quote = data['Global Quote']
                current_price = float(quote.get('05. price', 0))
                previous_close = float(quote.get('08. previous close', 0))
                
                if current_price > 0:
                    change = current_price - previous_close
                    change_percent = (change / previous_close * 100) if previous_close > 0 else 0
                    
                    return {
                        'current_value': current_price,
                        'previous_close': previous_close,
                        'change': change,
                        'change_percent': change_percent,
                        'last_update': datetime.now().isoformat(),
                        'source': 'Alpha Vantage',
                        'symbol': quote.get('01. symbol', 'VIX')
                    }
            
            logger.warning("Alpha Vantage data structure not recognized")
            return None
            
        except (KeyError, ValueError, TypeError) as e:
            logger.error(f"Error parsing Alpha Vantage data: {e}")
            return None

    def _parse_finnhub_data(self, data: Dict) -> Optional[Dict]:
        """è§£æFinnhub APIå“åº”"""
        try:
            current_price = float(data.get('c', 0))  # current price
            previous_close = float(data.get('pc', 0))  # previous close
            
            if current_price > 0:
                change = current_price - previous_close
                change_percent = (change / previous_close * 100) if previous_close > 0 else 0
                
                return {
                    'current_value': current_price,
                    'previous_close': previous_close,
                    'change': change,
                    'change_percent': change_percent,
                    'last_update': datetime.now().isoformat(),
                    'source': 'Finnhub',
                    'high': data.get('h', 0),
                    'low': data.get('l', 0),
                    'open': data.get('o', 0)
                }
            
            logger.warning("Finnhub data incomplete")
            return None
            
        except (KeyError, ValueError, TypeError) as e:
            logger.error(f"Error parsing Finnhub data: {e}")
            return None






    

    
    def _get_demo_vix_data(self) -> Dict:
        """è·å–æ™ºèƒ½æ¼”ç¤ºVIXæ•°æ® - æ¨¡æ‹ŸçœŸå®å¸‚åœºæƒ…å†µ"""
        import random
        from datetime import datetime, timedelta
        
        # åŸºäºå½“å‰æ—¶é—´ç”Ÿæˆæ›´çœŸå®çš„VIXæ•°æ®
        now = datetime.now()
        hour = now.hour
        
        # æ ¹æ®æ—¶é—´è°ƒæ•´VIXæ°´å¹³ï¼ˆå¼€ç›˜å’Œæ”¶ç›˜æ—¶é€šå¸¸è¾ƒé«˜ï¼‰
        if 9 <= hour <= 10 or 15 <= hour <= 16:  # å¼€ç›˜å’Œæ”¶ç›˜æ—¶é—´
            base_vix = random.uniform(20.0, 45.0)  # è¾ƒé«˜æ³¢åŠ¨
        elif 11 <= hour <= 14:  # äº¤æ˜“æ—¶é—´
            base_vix = random.uniform(15.0, 30.0)  # æ­£å¸¸æ³¢åŠ¨
        else:  # éäº¤æ˜“æ—¶é—´
            base_vix = random.uniform(12.0, 25.0)  # è¾ƒä½æ³¢åŠ¨
        
        # ç”Ÿæˆåˆç†çš„æ˜¨æ—¥æ”¶ç›˜ä»·
        previous_close = base_vix + random.uniform(-3.0, 3.0)
        previous_close = max(10.0, min(80.0, previous_close))  # é™åˆ¶åœ¨åˆç†èŒƒå›´å†…
        
        # è®¡ç®—å˜åŒ–
        change = base_vix - previous_close
        change_percent = (change / previous_close) * 100
        
        # æ·»åŠ å¸‚åœºæƒ…ç»ªæ ‡ç­¾
        if base_vix < 15:
            sentiment = "æä½æ³¢åŠ¨ - å¸‚åœºä¿¡å¿ƒå……è¶³"
        elif base_vix < 20:
            sentiment = "ä½æ³¢åŠ¨ - å¸‚åœºç›¸å¯¹å¹³é™"
        elif base_vix < 30:
            sentiment = "æ­£å¸¸æ³¢åŠ¨ - å¸‚åœºè¿è¡Œå¹³ç¨³"
        elif base_vix < 40:
            sentiment = "è¾ƒé«˜æ³¢åŠ¨ - å¸‚åœºå‡ºç°ä¸ç¡®å®šæ€§"
        else:
            sentiment = "é«˜æ³¢åŠ¨ - å¸‚åœºææ…Œæƒ…ç»ªä¸Šå‡"
        
        demo_data = {
            'current_value': round(base_vix, 2),
            'previous_close': round(previous_close, 2),
            'change': round(change, 2),
            'change_percent': round(change_percent, 2),
            'last_update': now.isoformat(),
            'source': 'æ™ºèƒ½æ¼”ç¤ºæ•°æ®',
            'is_demo': True,
            'sentiment': sentiment,
            'market_hours': 'äº¤æ˜“æ—¶é—´' if 9 <= hour <= 16 else 'éäº¤æ˜“æ—¶é—´'
        }
        
        logger.info(f"Generated intelligent demo VIX data: {demo_data}")
        return demo_data
    

    
    async def get_put_call_ratio(self) -> Optional[Dict]:
        """è·å– Put/Call æ¯”ç‡æ•°æ®"""
        try:
            # CBOE Put/Call æ¯”ç‡
            url = "https://www.cboe.com/us/options/market_statistics/daily/"
            
            async with self.session.get(url) as response:
                if response.status == 200:
                    html = await response.text()
                    return self._parse_put_call_data(html)
                    
        except Exception as e:
            logger.error(f"è·å– Put/Call æ¯”ç‡å¤±è´¥: {e}")
            
        return None
    
    def _parse_put_call_data(self, html: str) -> Dict:
        """è§£æ Put/Call æ¯”ç‡æ•°æ®"""
        try:
            soup = BeautifulSoup(html, 'html.parser')
            
            # è¿™é‡Œéœ€è¦æ ¹æ® CBOE ç½‘ç«™çš„å®é™…ç»“æ„æ¥è§£æ
            # ç”±äºç½‘ç«™ç»“æ„å¯èƒ½å˜åŒ–ï¼Œè¿™é‡Œæä¾›ä¸€ä¸ªåŸºç¡€æ¡†æ¶
            
            ratio = 1.0  # é»˜è®¤å€¼
            
            return {
                'ratio': ratio,
                'last_update': datetime.now().isoformat(),
                'interpretation': 'Neutral' if 0.8 <= ratio <= 1.2 else ('Bearish' if ratio > 1.2 else 'Bullish')
            }
            
        except Exception as e:
            logger.error(f"è§£æ Put/Call æ•°æ®å¤±è´¥: {e}")
            return {}
    
    async def get_market_breadth(self) -> Optional[Dict]:
        """è·å–å¸‚åœºå¹¿åº¦æ•°æ®"""
        try:
            # NYSE æ¶¨è·Œè‚¡ç¥¨æ•°æ®
            url = "https://www.marketwatch.com/investing/index/adv"
            
            async with self.session.get(url) as response:
                if response.status == 200:
                    html = await response.text()
                    return self._parse_market_breadth_data(html)
                    
        except Exception as e:
            logger.error(f"è·å–å¸‚åœºå¹¿åº¦æ•°æ®å¤±è´¥: {e}")
            
        return None
    
    def _parse_market_breadth_data(self, html: str) -> Dict:
        """è§£æå¸‚åœºå¹¿åº¦æ•°æ®"""
        try:
            soup = BeautifulSoup(html, 'html.parser')
            
            # åŸºç¡€æ•°æ®ï¼Œå®é™…éœ€è¦æ ¹æ®ç½‘ç«™ç»“æ„è°ƒæ•´
            advancing = 2000
            declining = 1500
            unchanged = 500
            
            total = advancing + declining + unchanged
            advance_decline_ratio = advancing / declining if declining > 0 else 1.0
            
            return {
                'advancing': advancing,
                'declining': declining,
                'unchanged': unchanged,
                'advance_decline_ratio': round(advance_decline_ratio, 2),
                'breadth_thrust': advance_decline_ratio > 2.0,
                'last_update': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"è§£æå¸‚åœºå¹¿åº¦æ•°æ®å¤±è´¥: {e}")
            return {}


async def fetch_all_indicators() -> Dict:
    """è·å–æ‰€æœ‰å¸‚åœºæŒ‡æ ‡"""
    async with FearGreedDataFetcher() as fetcher:
        results = {}
        
        # å¹¶å‘è·å–æ‰€æœ‰æ•°æ®
        tasks = [
            fetcher.get_current_fear_greed_index(),
            fetcher.get_vix_data(),
            fetcher.get_put_call_ratio(),
            fetcher.get_market_breadth()
        ]
        
        try:
            fear_greed, vix, put_call, breadth = await asyncio.gather(*tasks, return_exceptions=True)
            
            if not isinstance(fear_greed, Exception) and fear_greed:
                results['fear_greed'] = fear_greed
                
            if not isinstance(vix, Exception) and vix:
                results['vix'] = vix
                
            if not isinstance(put_call, Exception) and put_call:
                results['put_call'] = put_call
                
            if not isinstance(breadth, Exception) and breadth:
                results['market_breadth'] = breadth
                
        except Exception as e:
            logger.error(f"è·å–å¸‚åœºæŒ‡æ ‡æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            
        return results


# ä¾¿æ·å‡½æ•°
async def get_fear_greed_index() -> Optional[Dict]:
    """è·å–ææ…Œè´ªå©ªæŒ‡æ•°çš„ä¾¿æ·å‡½æ•°"""
    async with FearGreedDataFetcher() as fetcher:
        return await fetcher.get_current_fear_greed_index()


# å…¼å®¹æ€§åˆ«å
class DataFetcher(FearGreedDataFetcher):
    """DataFetcher å…¼å®¹æ€§åˆ«å"""
    
    async def get_current_fear_greed_index(self) -> Optional[Dict]:
        """è·å–å½“å‰ææ…Œè´ªå©ªæŒ‡æ•° - å…¼å®¹æ€§æ–¹æ³•"""
        # ä½¿ç”¨ context manager æ¥ç®¡ç† session
        async with self:
            data = await super().get_current_fear_greed_index()
            if data:
                # è½¬æ¢æ•°æ®æ ¼å¼ä»¥åŒ¹é… handlers.py çš„é¢„æœŸ
                return {
                    'score': data.get('current_value', 0),
                    'rating': data.get('rating', 'Unknown'),
                    'timestamp': data.get('last_update', ''),
                    'previous_close': data.get('previous_close'),
                    'week_ago': data.get('week_ago'),
                    'month_ago': data.get('month_ago'),
                    'year_ago': data.get('year_ago'),
                    'source': data.get('source', 'Unknown')
                }
            return None 